import numpy as np
from numpy import mean
import pickle
from scipy import stats
from scipy.stats import friedmanchisquare, rankdata
import pandas as pd

# df = pd.read_csv('data300.xlsx')
df = pd.read_excel('dataframe_friedman.xlsx')
# df = pd.read_csv('data.csv', usecols=['col1','col2','col3'])
# df = pd.read_csv('data.csv', skiprows=[1,2,3])
# df = pd.read_csv('data.csv', nrows=100)
# print(df)

#to print the dataframe as excel
# df_excel  = df.to_excel("dataframe2.xlsx")


#esme data ha ro hazf kon vase rank dadan
df1=df.iloc[:,1:]
print(df1)

#ye column ezafe mikone ke ranke column ie hast ke behesh dadim
# df1['column_name_rank'] = df1['LIT_KNORAE'].rank(method='min')
# print(df1)
# df_excel  = df1.to_excel("ttt.xlsx")


#ranking az kam ke mishe 1 be ziad-------axis0 baraye ranke beine data hast. axis1 baraye rank dar yek row
a = df1.rank(ascending=False, method='min',axis=1)
print(a)
# df_excel  = a.to_excel("ttt.xlsx")

#average rank of each columns
average_rank = a.sum(axis=0)/a.shape[0]
print("The average rank of each column is: ", average_rank)
# Create an empty dataframe
# df = pd.DataFrame(columns=['Column', 'Average Rank'])
# # Get the average rank of each column and add it to the dataframe
# for i, avg_rank in enumerate(a.mean(axis=0)):
#     df = df.append({'Column': i+1, 'Average Rank': avg_rank}, ignore_index=True)
#
# print(df)
#sort it in order
average_rank = a.sum(axis=0)/a.shape[0]
df = pd.DataFrame({'Column': list(range(1,a.shape[1]+1)), 'Average Rank': average_rank})
df = df.sort_values(by='Average Rank',ascending=True)
print(df)

#chand ta 1 dar har soton hast?
df_count = (a == 1).sum(axis=0)
# print(df_count)
#put it in order
df_count = df_count.sort_values(ascending=True)
print("-------------------------------------------------how many times we have 1th")
print(df_count)

#chand ta 1 va 2 hast?    3 ta aval ro uncomment konhesam age khasty
# df_count2 = a.eq(1).sum() + a.eq(2).sum()
df_count2 = a.eq(1).sum() + a.eq(2).sum() + a.eq(3).sum()
# print(df_count2)
df_count3 = df_count2.sort_values(ascending=True)
print("-------------------------------------------------")
# print(df_count3)

#friedman
from scipy.stats import friedmanchisquare
# extract the columns of interest
data = df1
# perform the Friedman test
stat, p = friedmanchisquare(*data.values.T)
print("-------------------------------------------------")
print(round(p, 4))       # ta 4 ragham aashar hesab mikone
# check the p-value
if p < 0.05:
    print("Reject null hypothesis, there is a significant difference among the columns.")
else:
    print("Fail to reject the null hypothesis, there is no significant difference among the columns.")

# #pairwise_tukeyhsd
# from statsmodels.stats.multicomp import pairwise_tukeyhsd
# data = df1.melt()
# # perform the Nemenyi test
# result = pairwise_tukeyhsd(data['value'], data['variable'])
# # print the result
# print(result.summary())
# result.summary().to_excel("output_tukeyhsd.xlsx")

#entekhabe chand column baraye mohayese pool ha dar yek method.  #df1 base hastesh hesam
knorae = df1.iloc[:, [1,9,17,25,33,41,49]]
METADES = df1.iloc[:, [2,10,18,26,34,42,50]]
KNORAU = df1.iloc[:, [3,11,19,27,35,43,51]]
DESMI = df1.iloc[:, [4,12,20,28,36,44,52]]
DESP = df1.iloc[:, [5,13,21,29,37,45,53]]
MLA = df1.iloc[:, [6,14,22,30,38,46,54]]
OLA = df1.iloc[:, [7,15,23,31,39,47,55]]
# algorithm = knorae
algorithm = METADES
# algorithm = KNORAU
# algorithm = DESMI
# algorithm = DESP
# algorithm = MLA
# algorithm = OLA
rank_knorae = algorithm.rank(ascending=False, method='min',axis=1)
# print(rank_knorae )
average_rank1 = rank_knorae.sum(axis=0)/a.shape[0]
# print("The average rank of each column is: ", average_rank1)
average_rank1_sorted = average_rank1.sort_values(ascending=True)
# print(average_rank1_sorted)


#mohayese flt ba baghiye#-----------------------------------------------------------------------------
FLT = df1.iloc[:, [49,50,51,52,53,54,55]]
LIT = df1.iloc[:, [1,2,3,4,5,6,7]]
# algorithm = FLT
algorithm = LIT
rank_knorae = algorithm.rank(ascending=False, method='min',axis=1)
# print(rank_knorae )
average_rank1 = rank_knorae.sum(axis=0)/a.shape[0]
# print("The average rank of each column is: ", average_rank1)
average_rank1_sorted = average_rank1.sort_values(ascending=True)
print(average_rank1_sorted)

#VASE har method ds kodom pool behtare vase har dataset
knorae = df1.iloc[:, [1,9,17,25,33,41,49]]
METADES = df1.iloc[:, [2,10,18,26,34,42,50]]
KNORAU = df1.iloc[:, [3,11,19,27,35,43,51]]
DESMI = df1.iloc[:, [4,12,20,28,36,44,52]]
DESP = df1.iloc[:, [5,13,21,29,37,45,53]]
MLA = df1.iloc[:, [6,14,22,30,38,46,54]]
OLA = df1.iloc[:, [7,15,23,31,39,47,55]]
MV = df1.iloc[:, [0,8,16,24,32,40,48]]
print(MV)
# algorithm = knorae
# algorithm = METADES
# algorithm = KNORAU
# algorithm = DESMI
# algorithm = DESP
# algorithm = MLA
algorithm = OLA
rank_knorae = algorithm.rank(ascending=False, method='min',axis=1)
print(rank_knorae )
knorae_rank1_count = (rank_knorae.eq(1, axis=0)).sum()
print(knorae_rank1_count)
# average_rank1_sorted = knorae_rank1_count.sort_values(ascending=False)
# print(average_rank1_sorted)
